{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_det.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d73Db4KbzCaF"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import cv2 "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ7z64pA3zLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d94bd25-5c70-4cb0-ad75-3d216357b9ca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFGq9wU_33eX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84088abf-93c3-43ca-de13-00da877dd576"
      },
      "source": [
        "cd '/content/gdrive/My Drive/Projects /RL_Driving/ld8/video files'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Projects /RL_Driving/ld8/video files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETWmQe4qzG0Y"
      },
      "source": [
        "#resize image  new_width=256, new_height=256,\n",
        "def prep_img(path):\n",
        "  size=(256,256)\n",
        "  img=cv2.imread(path)\n",
        "  cv2.resize(img, size)\n",
        "  return img\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yJnk82ezTJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0296222f-7291-49b2-da82-908c8d69fe0c"
      },
      "source": [
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
        "detector = hub.load(module_handle).signatures['default']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4aP8MaBzTtS"
      },
      "source": [
        "def run_detector(detector, path):\n",
        "  img = prep_img(path)\n",
        "\n",
        "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "  result = detector(converted_img)\n",
        "  #result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "  #print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "  #print(\"Inference time: \", end_time-start_time)\n",
        "  \n",
        "\n",
        "  \n",
        "  image_with_boxes = draw_boxes(\n",
        "      img, result[\"detection_boxes\"],\n",
        "      result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
        "  \n",
        "  return image_with_boxes"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WbsbM4qiUnI"
      },
      "source": [
        "classes_to_consider=['Car','Person','Land vehicle','Vehicle','Van','Truck']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW8LI2g_zu2a"
      },
      "source": [
        "def draw_boxes(image, boxes, class_names, scores):\n",
        "  #print(boxes)\n",
        "  y=image.shape[0]\n",
        "  x=image.shape[1]\n",
        "  \n",
        "  num=boxes.shape[0]\n",
        "  #print(num)\n",
        "  \n",
        "  for i in range (0,num):\n",
        "\n",
        "\n",
        "    #print(i)\n",
        "    det_score=scores[i].numpy()\n",
        "    \n",
        "    #print(det_score)\n",
        "\n",
        "    threshold=0.1\n",
        "    \n",
        "    if(det_score>threshold):\n",
        "\n",
        "      class_name=class_names[i].numpy()\n",
        "      #class_name=class_names[i]\n",
        "      class_name=str(class_name, 'UTF-8')\n",
        "      #if class_name in classes_li:\n",
        "      #  pass\n",
        "      #else:\n",
        "      #  classes_li.append(class_name)\n",
        "      #print(class_name)\n",
        "      if class_name in classes_to_consider:\n",
        "        box=boxes[i].numpy()\n",
        "        ymin=int(box[0]*y)\n",
        "        xmin=int(box[1]*x)\n",
        "        ymax=int(box[2]*y)\n",
        "        xmax=int(box[3]*x)\n",
        "        #print(i,\"c\")\n",
        "        \n",
        "        image=cv2.rectangle(image,(xmin,ymin),(xmax,ymax),(0,255,0),2)\n",
        "\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        org = (int((xmin+xmax)/2) ,int((ymin+ymax)/2))\n",
        "        fontScale = 1\n",
        "        color = (255, 0, 0)\n",
        "        thickness = 2\n",
        "        image = cv2.putText(image,class_name, org, font, \n",
        "                          fontScale, color, thickness, cv2.LINE_AA)\n",
        "    \n",
        "\n",
        "  return image "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBD0u1SX_PRg",
        "outputId": "6a799133-2a5d-4af8-bf2e-e5332ce7cd29"
      },
      "source": [
        "img=run_detector(detector,'520.jpg')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTGjRNLxNPKy",
        "outputId": "ec6cf779-5a5e-476e-8bc9-b0913013b080"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "output=\"t3_det.mp4\"\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Be sure to use lower case\n",
        "\n",
        "#frame = cv2.imread(\"520.jpg\")\n",
        "height, width, channels = img.shape\n",
        "out = cv2.VideoWriter(output, fourcc, 20.0, (width, height))\n",
        "\n",
        "# Opens the Video file\n",
        "i=0;\n",
        "#video_name=\"y.avi\"\n",
        "cap= cv2.VideoCapture('t3_full_results.mp4')\n",
        "#video = cv2.VideoWriter(video_name, 0, 1, (720, 1280)) \n",
        "while(cap.isOpened()):\n",
        "    i=i+1;\n",
        "    print(i);\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    cv2.imwrite('img'+'.jpg',frame)\n",
        "    img=run_detector(detector,'img.jpg')\n",
        "    #img=test(\"img.jpg\",\"res.txt\",griding_num)\n",
        "    out.write(img)\n",
        "    os.remove(\"img.jpg\")\n",
        "    #if(i==200):\n",
        "    #  break\n",
        "out.release()\n",
        "    \n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maUO7VJmTafT"
      },
      "source": [
        "blk = np.zeros(shape=[512, 512], dtype=np.uint8)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIKybrMoTxUc",
        "outputId": "c7b03e8e-4b08-4388-fed7-bac57c5d80ed"
      },
      "source": [
        "cv2.imwrite(\"y.jpg\",blk)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "TkiAzk1VFFuS",
        "outputId": "593fade8-1ce2-4fce-9428-d1eb5bbc4664"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(blk)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}